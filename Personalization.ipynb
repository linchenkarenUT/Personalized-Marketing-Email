{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: Run the basic model\n",
    "Using simple logistic regression and probit regression above helped us extract insights and understand how each variable impact the output. For instance, we found out that personalized as well as short emails are better, we should send emails on weekdays, etc. However, the fact that on an average short emails are better, doesnâ€™t imply that short emails are better for every user we have. \n",
    "\n",
    "Next, firstly, we'd like to approach the personalization problem. The goal of personalization is to take insights one step further and find the best email characteristics for each user. So a given user will receive a long email, another one a short one, one will receive it in the night, and one in the morning, etc.\n",
    "\n",
    "In this problem, we'd like to use Random Forest which is a strong classification algorithm to deal with binary classification problem. There's another point to make before we build the model. As EDA graph shows before, user past purchases has a long-tail distribution and we also bin the past purchases like hour to make Random Forest more efficient and easier to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.width', 350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed to be able to reproduce the results\n",
    "np.random.seed(2207)\n",
    "#read data\n",
    "data = pd.read_csv('emaildata.csv').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_id</th>\n",
       "      <th>email_text</th>\n",
       "      <th>email_version</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>user_country</th>\n",
       "      <th>user_past_purchases</th>\n",
       "      <th>clicked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>short_email</td>\n",
       "      <td>generic</td>\n",
       "      <td>9</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>US</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>long_email</td>\n",
       "      <td>personalized</td>\n",
       "      <td>6</td>\n",
       "      <td>Monday</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>short_email</td>\n",
       "      <td>generic</td>\n",
       "      <td>14</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>US</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>long_email</td>\n",
       "      <td>personalized</td>\n",
       "      <td>11</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>US</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>short_email</td>\n",
       "      <td>generic</td>\n",
       "      <td>8</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>UK</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   email_id   email_text email_version  hour    weekday user_country  user_past_purchases  clicked\n",
       "0         8  short_email       generic     9   Thursday           US                    3        0\n",
       "1        33   long_email  personalized     6     Monday           US                    0        0\n",
       "2        46  short_email       generic    14    Tuesday           US                    3        0\n",
       "3        49   long_email  personalized    11   Thursday           US                   10        0\n",
       "4        65  short_email       generic     8  Wednesday           UK                    3        0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have mentioned in `Probit` and `Logitistic` regression in R, it doesn't make sense to think that click through rate increases with hour and I'd like to bin hour to categorical features here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bin the variables according to the rules described above\n",
    "#Hour\n",
    "data['hour_binned'] = pd.cut(data['hour'], bins=[1,5,13,21,24],\n",
    "                                include_lowest=True, labels=['night','morning', 'afternoon', 'night2'])\n",
    "data['hour_binned'] = data['hour_binned'].replace('night2','night').cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I transform numerical feature `user_past_purchases` to categorical as well. EDA shows `user_past_purchases` have a long-tail distribution and it would be easier to use this feature in categorical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bin purchases\n",
    "data['purchase_binned'] = pd.cut(data['user_past_purchases'], bins=[0,1,4,8,23],\n",
    "                                    include_lowest=True, right=False, labels=['None', 'Low', 'Medium', 'High'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the data for the model\n",
    "data_dummy = pd.get_dummies(data, drop_first=True)\\\n",
    "                .drop(['email_id', 'hour', 'user_past_purchases'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99950, 17)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dummy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97881, 17)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dummy[data_dummy.clicked==0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the click through rate of the email in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021137912362971363"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_dummy.shape[0] - data_dummy[data_dummy.clicked==0].shape[0])/data_dummy[data_dummy.clicked==0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and test to avoid overfitting\n",
    "train, test = train_test_split(data_dummy, test_size=0.34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the random forest model. Since the click through rate only accounts for 2 percent, it's an imbalance dataset that require to adjust the `class_weight`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                       class_weight={0: 0.05, 1: 0.95}, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       max_samples=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=50, n_jobs=None, oob_score=True,\n",
       "                       random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model. We choose a RF, but this personalization approach works\n",
    "# with any kinds of models as long as it deals with category problem\n",
    "\n",
    "# imbalanced data\n",
    "rf = RandomForestClassifier(class_weight={0:0.05, 1:0.95},\n",
    "                           n_estimators=50, oob_score=True)\n",
    "rf.fit(train.drop('clicked', axis=1), train['clicked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0     1\n",
      "0  58849  5728\n",
      "1   1071   319\n"
     ]
    }
   ],
   "source": [
    "#let's print OOB confusion matrix\n",
    "print(pd.DataFrame(confusion_matrix(train['clicked'],\n",
    "                                       rf.oob_decision_function_[:,1].round(), labels=[0,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0     1\n",
      "0  30518  2786\n",
      "1    525   154\n"
     ]
    }
   ],
   "source": [
    "#and let's print test set confusion matrix\n",
    "print(pd.DataFrame(confusion_matrix(test['clicked'],\n",
    "                                       rf.predict(test.drop('clicked', axis=1)),\n",
    "                                       labels=[0,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define two terminology, class 0 error and class 1 error. \n",
    "\n",
    "`class 0 error` is the probability of being incorrectly labeled as 1 while its true label is 0.\n",
    "\n",
    "`class 1 error` is the probability of being incorrectly labeled as 0 while its true label is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OOB and test error are very similar, so we are confident we are not overfitting. And overall the model is working pretty well. We only had 2% of clicks, but despite that the model is not predicting all events as class 0, we actually manage to predict ~21% of clicks. And class 0 error didnâ€™t go up that much either, being around 8%.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21207658321060383"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "144/(144+535)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08092121066538555"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2695/(30609+2695)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Predict click-through-rate for each segment\n",
    "\n",
    "The second step is to create a new dataset with all unique combinations of our variables. We will then feed this dataset into the model and, for each unique combination, we will get a prediction. The model prediction represents click-rate and, therefore, this step is meant to estimate probability of clicking for each unique combination of country, # of purchases, email text, weekday, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_text_short_email</th>\n",
       "      <th>email_version_personalized</th>\n",
       "      <th>weekday_Monday</th>\n",
       "      <th>weekday_Saturday</th>\n",
       "      <th>weekday_Sunday</th>\n",
       "      <th>weekday_Thursday</th>\n",
       "      <th>weekday_Tuesday</th>\n",
       "      <th>weekday_Wednesday</th>\n",
       "      <th>user_country_FR</th>\n",
       "      <th>user_country_UK</th>\n",
       "      <th>user_country_US</th>\n",
       "      <th>hour_binned_morning</th>\n",
       "      <th>hour_binned_afternoon</th>\n",
       "      <th>purchase_binned_Low</th>\n",
       "      <th>purchase_binned_Medium</th>\n",
       "      <th>purchase_binned_High</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.293623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.194953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   email_text_short_email  email_version_personalized  weekday_Monday  weekday_Saturday  weekday_Sunday  weekday_Thursday  weekday_Tuesday  weekday_Wednesday  user_country_FR  user_country_UK  user_country_US  hour_binned_morning  hour_binned_afternoon  purchase_binned_Low  purchase_binned_Medium  purchase_binned_High  prediction\n",
       "0                       1                           0               0                 0               0                 1                0                  0                0                0                1                    1                      0                    1                       0                     0    0.293623\n",
       "1                       0                           1               1                 0               0                 0                0                  0                0                0                1                    1                      0                    0                       0                     0    0.000000\n",
       "2                       1                           0               0                 0               0                 0                1                  0                0                0                1                    0                      1                    1                       0                     0    0.194953"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we remove the label, we don't need it here\n",
    "data_unique = data_dummy.drop(['clicked'], axis=1)\n",
    "\n",
    "#we create all unique combinations of our features\n",
    "data_unique = data_unique.drop_duplicates()\n",
    "\n",
    "#Now we feed this into our model and get a prediction for each row\n",
    "predictions = rf.predict_proba(data_unique)\n",
    "\n",
    "#Finally, we add these predictions to the dataset\n",
    "data_unique['prediction'] = [x[1] for x in predictions]\n",
    "\n",
    "data_unique.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, looking at the first row in the table output, if we send a short email, generic, in the morning, on Thursday, to US customers with few purchases, our model predicts no clicks. And so on for each row. For each unique segment, we have got the probability of clicking.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Identify the best email characteristics for each user\n",
    "\n",
    "The third step is to identify the variables that can be personalized. This typically means separating user characteristics from product characteristics, and focus on the second ones. After all, you can choose when to send the email or its message, but you canâ€™t realistically move a customer from Spain to UK.\n",
    "\n",
    "Then, we group by unique combinations of user characteristics and find the product characteristics with the highest probability of clicking. So, for instance, one group will be US customers with 0 purchases (these are user characteristics). And then we will look for the combination of all the other variables that maximize probability of clicking. And thatâ€™s it. That combination will tell us how our product should be for those users and we will send emails accordingly. The more variables you have about your users, the more granular will be the groups and, therefore, the more specific will be the personalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort by prediction. This way highest predictions will be at the \n",
    "#top of the dataset\n",
    "data_unique = data_unique.sort_values('prediction', ascending=False)\n",
    "\n",
    "#Remove duplicates for country and purchase binned. This way, for\n",
    "#each unique combination of country and purchases, we will only\n",
    "#have the top 1 value, which means the highest prediction\n",
    "best_segment = data_unique.drop_duplicates(subset=['user_country_FR', 'user_country_UK',\n",
    "                                                  'user_country_US', 'purchase_binned_Low', 'purchase_binned_Medium',\n",
    "                                                  'purchase_binned_High']).copy()\n",
    "#Country\n",
    "#Unbin the dummy \n",
    "best_segment['user_country'] = np.where(best_segment['user_country_UK']==1,\"UK\",\n",
    "                                       np.where(best_segment['user_country_US']==1, \"US\",\n",
    "                                               np.where(best_segment['user_country_FR']==1, \"FR\", \"ES\")))\n",
    "best_segment = best_segment.drop([e for e in list(data_unique) if e.startswith('user_country_')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number_purchases\n",
    "best_segment['purchase_binned'] = np.where(best_segment['purchase_binned_High']==1, 'High',\n",
    "                                          np.where(best_segment['purchase_binned_Medium']==1, 'Medium',\n",
    "                                                  np.where(best_segment['purchase_binned_Low']==1, 'Low', 'None')))\n",
    "best_segment = best_segment.drop([e for e in list(best_segment) if e.startswith('purchase_binned_')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_text_short_email</th>\n",
       "      <th>email_version_personalized</th>\n",
       "      <th>weekday_Monday</th>\n",
       "      <th>weekday_Saturday</th>\n",
       "      <th>weekday_Sunday</th>\n",
       "      <th>weekday_Thursday</th>\n",
       "      <th>weekday_Tuesday</th>\n",
       "      <th>weekday_Wednesday</th>\n",
       "      <th>hour_binned_morning</th>\n",
       "      <th>hour_binned_afternoon</th>\n",
       "      <th>prediction</th>\n",
       "      <th>user_country</th>\n",
       "      <th>purchase_binned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.776802</td>\n",
       "      <td>ES</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6151</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.775957</td>\n",
       "      <td>UK</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.765293</td>\n",
       "      <td>US</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7361</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.689690</td>\n",
       "      <td>FR</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.624446</td>\n",
       "      <td>UK</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      email_text_short_email  email_version_personalized  weekday_Monday  weekday_Saturday  weekday_Sunday  weekday_Thursday  weekday_Tuesday  weekday_Wednesday  hour_binned_morning  hour_binned_afternoon  prediction user_country purchase_binned\n",
       "55                         1                           1               0                 0               0                 0                1                  0                    1                      0    0.776802           ES            High\n",
       "6151                       1                           1               1                 0               0                 0                0                  0                    0                      0    0.775957           UK            High\n",
       "751                        1                           1               0                 1               0                 0                0                  0                    0                      0    0.765293           US            High\n",
       "7361                       1                           1               1                 0               0                 0                0                  0                    1                      0    0.689690           FR            High\n",
       "448                        1                           0               0                 0               0                 1                0                  0                    1                      0    0.624446           UK          Medium"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_segment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Email version\n",
    "best_segment['email_version'] = np.where(best_segment['email_version_personalized']==1, 'personalized',\n",
    "                                        'generic')\n",
    "best_segment = best_segment.drop('email_version_personalized', axis=1)\n",
    "\n",
    "#Email text\n",
    "best_segment['email_text'] = np.where(best_segment['email_text_short_email']==1,'short_email', 'long_email')\n",
    "best_segment = best_segment.drop('email_text_short_email', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weekday\n",
    "best_segment['weekday'] = np.where(best_segment['weekday_Monday'] == 1, \"Monday\", \n",
    "                                    np.where(best_segment['weekday_Saturday'] == 1, \"Saturday\", \n",
    "                                       np.where(best_segment['weekday_Sunday'] == 1, \"Sunday\",\n",
    "                                          np.where(best_segment['weekday_Thursday'] == 1, \"Thursday\", \n",
    "                                              np.where(best_segment['weekday_Tuesday'] == 1, \"Tuesday\",\n",
    "                                                   np.where(best_segment['weekday_Wednesday'] == 1, \"Wednesday\",\n",
    "                                                      \"Friday\"\n",
    "))))))\n",
    "best_segment = best_segment.drop([e for e in list(data_unique) if e.startswith('weekday_')], axis=1)      \n",
    "\n",
    "#Hour\n",
    "best_segment['hour_binned'] = np.where(best_segment['hour_binned_afternoon']==1, 'afternoon',\n",
    "                                      np.where(best_segment['hour_binned_morning']==1, 'morning', 'night'))\n",
    "best_segment = best_segment.drop([e for e in list(data_unique) if e.startswith('hour_binned_')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>user_country</th>\n",
       "      <th>purchase_binned</th>\n",
       "      <th>email_version</th>\n",
       "      <th>email_text</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour_binned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.776802</td>\n",
       "      <td>ES</td>\n",
       "      <td>High</td>\n",
       "      <td>personalized</td>\n",
       "      <td>short_email</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6151</th>\n",
       "      <td>0.775957</td>\n",
       "      <td>UK</td>\n",
       "      <td>High</td>\n",
       "      <td>personalized</td>\n",
       "      <td>short_email</td>\n",
       "      <td>Monday</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>0.765293</td>\n",
       "      <td>US</td>\n",
       "      <td>High</td>\n",
       "      <td>personalized</td>\n",
       "      <td>short_email</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7361</th>\n",
       "      <td>0.689690</td>\n",
       "      <td>FR</td>\n",
       "      <td>High</td>\n",
       "      <td>personalized</td>\n",
       "      <td>short_email</td>\n",
       "      <td>Monday</td>\n",
       "      <td>morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0.624446</td>\n",
       "      <td>UK</td>\n",
       "      <td>Medium</td>\n",
       "      <td>generic</td>\n",
       "      <td>short_email</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>morning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prediction user_country purchase_binned email_version   email_text   weekday hour_binned\n",
       "55      0.776802           ES            High  personalized  short_email   Tuesday     morning\n",
       "6151    0.775957           UK            High  personalized  short_email    Monday       night\n",
       "751     0.765293           US            High  personalized  short_email  Saturday       night\n",
       "7361    0.689690           FR            High  personalized  short_email    Monday     morning\n",
       "448     0.624446           UK          Medium       generic  short_email  Thursday     morning"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_segment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have a model that returns the best email strategy for each user and thatâ€™s how we should be sending email to maximize overall click-through-rate. Btw note how even the best email strategy has super low model predictions for users with no purchases, regardless of the country. Once again, you wonâ€™t win those people just by tweaking the email.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Estimate A/B test gains from the result so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have come up with a personalized strategy to send emails, the last step is to test it. We don't have the chance to run a A/B testing and we can provide some insights based on what we've got! We would run our personalized algorithm on a randomized fraction of users and compare its results with the current email strategy. Since we know the predicted probability for each group, we can just estimate the weighted average to guess the final overall click rate.\n",
    "\n",
    "Our model isnâ€™t a perfect one and has pretty high class one error so we need to adjust the predicted probabilities after taking into account the model expected error.\n",
    "\n",
    "We can do it as fellow:\n",
    "Assume, for instance, that our model output is 0.8, so it is predicting 80% clicks. Based on the confusion matrix when we built the model, that when our model predicts class 1 is right 5% of the times and when it predicts class 0 is wrong 2% of the times. So if our model is predicting 80% class 1 (and therefore 20% class 0), am actually expecting: 0.8 * 0.05 + 0.2*0.02 = 0.044 = 4.4%. It still isnâ€™t a big click rate but would still be a huge improvement because our starting point is 2.07% in EDA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Firstly, let's get count by group. We need this for the weighted average at the end\n",
    "count_segment = data[['user_country', 'purchase_binned']].groupby(['user_country', 'purchase_binned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_country</th>\n",
       "      <th>purchase_binned</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ES</td>\n",
       "      <td>None</td>\n",
       "      <td>1368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ES</td>\n",
       "      <td>Low</td>\n",
       "      <td>3785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ES</td>\n",
       "      <td>Medium</td>\n",
       "      <td>3389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ES</td>\n",
       "      <td>High</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FR</td>\n",
       "      <td>None</td>\n",
       "      <td>1341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_country purchase_binned  counts\n",
       "0           ES            None    1368\n",
       "1           ES             Low    3785\n",
       "2           ES          Medium    3389\n",
       "3           ES            High    1422\n",
       "4           FR            None    1341"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_segment = count_segment.size().reset_index(name='counts')\n",
    "count_segment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>user_country</th>\n",
       "      <th>purchase_binned</th>\n",
       "      <th>email_version</th>\n",
       "      <th>email_text</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour_binned</th>\n",
       "      <th>counts</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.776802</td>\n",
       "      <td>ES</td>\n",
       "      <td>High</td>\n",
       "      <td>personalized</td>\n",
       "      <td>short_email</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>morning</td>\n",
       "      <td>1422</td>\n",
       "      <td>0.014227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.775957</td>\n",
       "      <td>UK</td>\n",
       "      <td>High</td>\n",
       "      <td>personalized</td>\n",
       "      <td>short_email</td>\n",
       "      <td>Monday</td>\n",
       "      <td>night</td>\n",
       "      <td>2712</td>\n",
       "      <td>0.027134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.765293</td>\n",
       "      <td>US</td>\n",
       "      <td>High</td>\n",
       "      <td>personalized</td>\n",
       "      <td>short_email</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>night</td>\n",
       "      <td>8325</td>\n",
       "      <td>0.083292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.689690</td>\n",
       "      <td>FR</td>\n",
       "      <td>High</td>\n",
       "      <td>personalized</td>\n",
       "      <td>short_email</td>\n",
       "      <td>Monday</td>\n",
       "      <td>morning</td>\n",
       "      <td>1444</td>\n",
       "      <td>0.014447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.624446</td>\n",
       "      <td>UK</td>\n",
       "      <td>Medium</td>\n",
       "      <td>generic</td>\n",
       "      <td>short_email</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>morning</td>\n",
       "      <td>6622</td>\n",
       "      <td>0.066253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction user_country purchase_binned email_version   email_text   weekday hour_binned  counts    weight\n",
       "0    0.776802           ES            High  personalized  short_email   Tuesday     morning    1422  0.014227\n",
       "1    0.775957           UK            High  personalized  short_email    Monday       night    2712  0.027134\n",
       "2    0.765293           US            High  personalized  short_email  Saturday       night    8325  0.083292\n",
       "3    0.689690           FR            High  personalized  short_email    Monday     morning    1444  0.014447\n",
       "4    0.624446           UK          Medium       generic  short_email  Thursday     morning    6622  0.066253"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the proportion instead of the counts. Just easier to deal\n",
    "#with average at the end\n",
    "count_segment['weight'] = count_segment['counts'].div(count_segment['counts'].sum())\n",
    "\n",
    "\n",
    "best_segment = pd.merge(best_segment, count_segment).sort_values('prediction', ascending=False)\n",
    "\n",
    "best_segment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's add class1 and class0 errors to the dataset.\n",
    "#We will take it from the test error confusion matrix.\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(test['clicked'],\n",
    "                                           rf.predict(test.drop('clicked', axis=1)),\n",
    "                                           labels=[0,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30518</td>\n",
       "      <td>2786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>525</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1\n",
       "0  30518  2786\n",
       "1    525   154"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define some terminology for us to come up with the new click through rate.\n",
    "\n",
    "`positive predictive value(ppv)`: the proportion of times the model is right when it predicts 1. (We can call it precion as well.\n",
    "`false omission rate(for)`: those are actual clicks that the model is mistakenly predicting a non-click.\n",
    "\n",
    "The estimated click through rate using the model: $prob*ppv + (1-prob)*for$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ppv\n",
    "ppv = conf_matrix.loc[1,1]/(conf_matrix.loc[1,1]+conf_matrix.loc[0,1])\n",
    "\n",
    "#for\n",
    "forate = conf_matrix.loc[1,0]/(conf_matrix.iloc[1,0]+conf_matrix.iloc[0,0])\n",
    "\n",
    "#Adjusted predicted click-rate for each segment\n",
    "best_segment['adjusted_prediction'] = best_segment['prediction'] * ppv + \\\n",
    "                                    (1-best_segment['prediction']) * forate\n",
    "\n",
    "#Finally, let's multiply this by the weight of each segment in the dataset and compare it with the starting click-rate\n",
    "CTR_comparison = pd.DataFrame({'predicted_click_rate':[(best_segment['adjusted_prediction']*best_segment['weight']).sum()],\n",
    "                                  'old_click_rate':[data['clicked'].mean()]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_click_rate</th>\n",
       "      <th>old_click_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035287</td>\n",
       "      <td>0.0207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted_click_rate  old_click_rate\n",
       "0              0.035287          0.0207"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CTR_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
